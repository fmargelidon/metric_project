# Metric project

This project have 4 sub-project to collect, store and display metrics

## 1- collector

This sub-project is a shell script which collect metadata which are event time and hostname.
This script collect metrics like server average load for 1min, pid, process name,
rss memory and elapsed time in seconds.

This script needs to be schedule in crontab to be executed every 5min to generate.
Json output in folder given in parameter.

For example :
```bash
*/5 * * * * /full_path/collect-metrics.sh /tmp/metrics
```

You can find some json output files example in collector/examples folder.

## 2- database

This sub-project contains configuration file to start postgreSQL in docker.

To start database :

```bash
$ docker compose up -d postgres
```

To stop database :

```bash
$ docker-compose down postgres
```

It will build postgreSQL database and execute sql/*.sql to create and initialize all 
tables required to store all result from collect-metrics.sh thanks to sub-project
aggregator which are a Java daemon.

You can connect on database with credential postgres/postgres and on default port
5432.

## 3- aggregator

This Java daemon scan all json file generated by collect-metrics.sh and insert 
result in postgreSQL database. It is possible to select which folder to scan 
if you modify Dockerfile a replace metrics folder by the one you want to link
into container.

To build jar :
```bash
$ mvn clean package
```

To launch docker daemon :
```bash
$ docker compose up aggregator
```

## 4 - monitoring

This docker configuration file allow you to launch a grafana interface and 
display all metrics store in postgreSQL database. 
You can see server average load over time, and top 5 process for rss memory
and elapsed time thanks to predefine dashboard.

To start grafana :
```bash
$ docker compose up grafana
```